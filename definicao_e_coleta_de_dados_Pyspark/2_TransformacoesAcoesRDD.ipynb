{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Configuração Inicial e Contexto"
      ],
      "metadata": {
        "id": "HQDnaQVUftUW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fe7HmY-WKrc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c68d432e-2e5d-4c61-9482-32c6fc4e3f49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark #Instala o PySpark no ambiente Colab, permitindo que o Python interaja com o Apache Spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark #Importa a biblioteca PySpark para acesso às suas funcionalidades\n",
        "from pyspark import SparkContext, SparkConf #Importa as classes principais: SparkContext (ponto de entrada) e SparkConf (para configurar o contexto)"
      ],
      "metadata": {
        "id": "XJlQFtJRK2YU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conf = SparkConf().setAppName(\"leitura de arquivo texto\") #Cria uma configuração (SparkConf) e define um nome amigável para a aplicação Spark (neste caso, \"leitura de arquivo texto\")\n",
        "sc = SparkContext(conf=conf).getOrCreate() #Cria ou obtém o SparkContext. Ele usa a configuração definida (conf) e é o objeto que conecta o código ao cluster Spark"
      ],
      "metadata": {
        "id": "Wqm1RDKaLFf6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leitura de Dados"
      ],
      "metadata": {
        "id": "faWHSwGVf2mI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2559b06e"
      },
      "source": [
        "rdd = sc.textFile(\"sample_data/README.md\") #Cria um RDD lendo o conteúdo de um arquivo de texto (README.md) linha por linha. Cada linha do arquivo se torna um elemento no RDD"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ações e Transformações Básicas"
      ],
      "metadata": {
        "id": "8Sy2CVtFf8pj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c774cf2e",
        "outputId": "15fc90e7-a0d2-4244-f631-0afe8932cb2e"
      },
      "source": [
        "rdd.count() #Retorna o número total de linhas (elementos) no RDD."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "619d883b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f28b8ad-5d42-4ad8-c4e4-2791b468aab1"
      },
      "source": [
        "rdd.take(10) #Retorna uma lista com as primeiras 10 linhas do arquivo de texto."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This directory includes a few sample datasets to get you started.',\n",
              " '',\n",
              " '*   `california_housing_data*.csv` is California housing data from the 1990 US',\n",
              " '    Census; more information is available at:',\n",
              " '    https://docs.google.com/document/d/e/2PACX-1vRhYtsvc5eOR2FWNCwaBiKL6suIOrxJig8LcSBbmCbyYsayia_DvPOOBlXZ4CAlQ5nlDD8kTaIDRwrN/pub',\n",
              " '',\n",
              " '*   `mnist_*.csv` is a small sample of the',\n",
              " '    [MNIST database](https://en.wikipedia.org/wiki/MNIST_database), which is',\n",
              " '    described at: http://yann.lecun.com/exdb/mnist/',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "475193b2"
      },
      "source": [
        "palavra = rdd.flatMap(lambda x:x.split(' ')) #(flatMap): Transforma o RDD de linhas (rdd) em um RDD de palavras individuais.\n",
        "                                             #O split(' ') divide cada linha por espaços, e o flatMap achata o resultado, garantindo que a saída seja um único RDD de palavras, em vez de um RDD de listas de palavras."
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0744aa01",
        "outputId": "b46e9095-7caa-4ec4-a6cf-541c910f99f6"
      },
      "source": [
        "palavraMinuscula = palavra.map(lambda x: x.lower()) #(map): Aplica a função lower() (converter para minúsculas) a cada palavra no RDD, criando um novo RDD de palavras em minúsculas\n",
        "print('Map: ', palavraMinuscula.take(5)) #Imprime as 5 primeiras palavras do RDD em minúsculas.\n",
        "\n",
        "palavraMinusculaFlatMap = palavra.flatMap(lambda x: x.upper()) #(flatMap): Aplica a função upper() (converter para maiúsculas) a cada palavra.\n",
        "                                                               #Importante: Como flatMap espera uma sequência de retorno, ele quebra cada palavra em caracteres individuais em maiúsculas\n",
        "\n",
        "print('flatMap: ', palavraMinusculaFlatMap.take(5)) #Imprime os primeiros 5 caracteres resultantes do flatMap em maiúsculas."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Map:  ['this', 'directory', 'includes', 'a', 'few']\n",
            "flatMap:  ['T', 'H', 'I', 'S', 'D']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7774ea8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87cf9914-1ae8-4f53-c5e9-92343e9f9098"
      },
      "source": [
        "palavraComecaT = palavraMinuscula.filter(lambda x: x.startswith('t')) #(filter): Cria um novo RDD contendo apenas as palavras que começam com a letra 't'.\n",
        "print(palavraComecaT.take(5)) # Exibe as 5 primeiras palavras que começam com 't'.\n",
        "\n",
        "palavraMin2 = palavraMinuscula.filter(lambda x: len(x) > 2) # (filter): Cria um novo RDD removendo palavras com 1 ou 2 caracteres (geralmente preposições, artigos ou strings vazias)\n",
        "print(palavraMin2.take(5)) #Exibe as 5 primeiras palavras com mais de 2 caracteres."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['this', 'to', 'the', 'the', 'the']\n",
            "['this', 'directory', 'includes', 'few', 'sample']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contagem de Palavras (Word Count)"
      ],
      "metadata": {
        "id": "n5mUkwYLgEuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palavraChaveValor = palavraMin2.map(lambda x: (x,1)) #(map):Converte o RDD de palavras em um RDD de pares chave-valor (Tuplas). Cada palavra se torna a chave e o valor 1 é anexado, preparando para a contagem\n",
        "palavraChaveValor.take(5) #Exibe os 5 primeiros pares chave-valor."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eIzA32p0OUj",
        "outputId": "874ff22c-575f-4f69-8070-0aa0fb56346e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('this', 1), ('directory', 1), ('includes', 1), ('few', 1), ('sample', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "palavraContar = palavraChaveValor.reduceByKey(lambda x, y: x+y) # (reduceByKey): Agrupa todos os valores pela chave (palavra) e aplica uma função de agregação (neste caso, soma os valores 1), resultando na contagem final de cada palavra\n",
        "palavraContarOrd = palavraContar.sortByKey(ascending=-1) #(sortByKey): Ordena o resultado da contagem de palavras com base na chave (a própria palavra)\n",
        "palavraContar.take(20) #Exibe as 20 primeiras palavras e suas contagens, na ordem em que o Spark as processou (não ordenadas)."
      ],
      "metadata": {
        "collapsed": true,
        "id": "xCxtPXwi0jJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8159863-4faa-4381-e0a8-b5cf337a7396"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('this', 1),\n",
              " ('sample', 2),\n",
              " ('datasets', 1),\n",
              " ('you', 1),\n",
              " ('started.', 1),\n",
              " ('`california_housing_data*.csv`', 1),\n",
              " ('from', 1),\n",
              " ('1990', 1),\n",
              " ('more', 1),\n",
              " ('information', 1),\n",
              " ('available', 1),\n",
              " ('small', 1),\n",
              " ('database](https://en.wikipedia.org/wiki/mnist_database),', 1),\n",
              " ('described', 2),\n",
              " (\"[anscombe's\", 1),\n",
              " ('statistical', 1),\n",
              " (\"analysis'.\", 1),\n",
              " ('american', 1),\n",
              " ('jstor', 1),\n",
              " ('2682899.', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salvamento e Leitura de Resultados"
      ],
      "metadata": {
        "id": "TlCEa53EgM2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palavraContar.saveAsTextFile(\"contar_palavras_out\") #O Spark salvará o resultado em vários arquivos de saída dentro deste diretório, um por partição."
      ],
      "metadata": {
        "id": "jFBqXMF11GmU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls contar_palavras_out/ #Comando Shell: Lista o conteúdo do diretório de saída para confirmar que os arquivos foram criados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydyIrVh01Rzr",
        "outputId": "4a4c3bae-cabb-4c56-8c15-9bf6e2480454"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000  part-00001\t_SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "09407835"
      },
      "source": [
        "rddContarPalavras = sc.textFile(\"contar_palavras_out\") #Cria um novo RDD lendo os arquivos de texto que acabaram de ser salvos no diretório de saída."
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}