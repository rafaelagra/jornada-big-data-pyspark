{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Configuração e Importação"
      ],
      "metadata": {
        "id": "QBslXtKegmYZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LU_-3Eoh-7vh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bedd9bab-71ff-4e1b-e4ea-0bf946672f94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark #Instala o PySpark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark #Importa a biblioteca PySpark para que suas funcionalidades fiquem disponíveis no código Python.\n",
        "from pyspark import SparkContext #Importa especificamente a classe SparkContext da biblioteca PySpark"
      ],
      "metadata": {
        "id": "nbsmV0NPADed"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os #usado para interagir com o sistema operacional (como definir variáveis de ambiente).\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\" #Define a variável de ambiente JAVA_HOME.\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null #Instala o Java Development Kit (JDK) 8\n",
        "\n",
        "sc = SparkContext.getOrCreate() #Cria ou obtém um SparkContext."
      ],
      "metadata": {
        "id": "kWnJFRtSADwg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicialização do Spark e RDDs"
      ],
      "metadata": {
        "id": "_6TqVXi0gzbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1,2,3,4,5,6,7,8,9,10]) #Cria um RDD a partir de uma lista Python. O método parallelize distribui essa coleção de dados em partições para processamento paralelo"
      ],
      "metadata": {
        "id": "D49LKcQNAGLt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ações e Transformações em RDDs"
      ],
      "metadata": {
        "id": "uBP42X0og9aW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.getNumPartitions() #Retorna o número de partições em que o RDD foi dividido para processamento paralelo."
      ],
      "metadata": {
        "id": "1rwC9khLAGZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65cfb9b-552d-4af3-9af7-dc4f304c9358"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.first #Retorna o primeiro elemento do RDD."
      ],
      "metadata": {
        "id": "J91f8rtYAG2T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "65813371-aef9-47b1-8083-1bfd1828bbaa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method RDD.first of ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:289>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.RDD.first</b><br/>def first() -&gt; T</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/rdd.py</a>Return the first element in this RDD.\n",
              "\n",
              ".. versionadded:: 0.7.0\n",
              "\n",
              "Returns\n",
              "-------\n",
              "T\n",
              "    the first element\n",
              "\n",
              "See Also\n",
              "--------\n",
              ":meth:`RDD.take`\n",
              ":meth:`pyspark.sql.DataFrame.first`\n",
              ":meth:`pyspark.sql.DataFrame.head`\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; sc.parallelize([2, 3, 4]).first()\n",
              "2\n",
              "&gt;&gt;&gt; sc.parallelize([]).first()\n",
              "Traceback (most recent call last):\n",
              "    ...\n",
              "ValueError: RDD is empty</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 2862);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.take(5) #Retorna uma lista com os primeiros 5 elementos do RDD."
      ],
      "metadata": {
        "id": "eg6jNvr5AHfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "149a3cb2-da51-4d16-d690-a8feaa19b04d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.collect() #cuidado #Retorna todos os elementos do RDD como uma lista Python."
      ],
      "metadata": {
        "id": "AG3GFuqwAHy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28add2b1-7707-49dc-91dd-4dc00333112a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rddTexto = sc.parallelize([\"Spark\",\"Hadoop\",\"Python\",\"Spark\",\"Hadoop\"]) #Cria um novo RDD de strings."
      ],
      "metadata": {
        "id": "WgxRKF8ZAHND"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def funcMin(palavra): #Define uma função Python para converter uma string para minúsculas.\n",
        "  palavra = palavra.lower()\n",
        "  return palavra\n",
        "\n",
        "  rddMinuscula = rddTexto.map(funcMin) #Aplica a função funcMin a cada elemento do rddTexto, criando um novo RDD. map é uma transformação comum.\n",
        "  rddMinuscula.take(5) #Exibe os primeiros 5 elementos do RDD transformado (rddMinuscula)."
      ],
      "metadata": {
        "id": "BQXohm7xAIkl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rddMinuscula_1 = rddTexto.map(lambda x: x.lower()) #Faz o mesmo que a linha anterior, mas usando uma função anônima (lambda), que é mais concisa e comum em PySpark.\n",
        "\n",
        "rddMinuscula_1.take(5) #Exibe os primeiros 5 elementos do segundo RDD transformado."
      ],
      "metadata": {
        "id": "cWjOI6XyAJIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca61f183-50bb-4499-cd5a-9b828aa94a14"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['spark', 'hadoop', 'python', 'spark', 'hadoop']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalização"
      ],
      "metadata": {
        "id": "A51H07xOhOpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop #Encerra o SparkContext e libera os recursos alocados, finalizando a sessão do Spark."
      ],
      "metadata": {
        "id": "fXKnF5XGChZQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "de8aff42-9faf-41bb-c7b7-7ca2d2bbfd26"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method SparkContext.stop of <SparkContext master=local[*] appName=pyspark-shell>>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.context.SparkContext.stop</b><br/>def stop() -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/context.py</a>Shut down the :class:`SparkContext`.\n",
              "\n",
              ".. versionadded:: 0.7.0</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 646);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}