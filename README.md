# üß≠ Jornada Big Data com PySpark  
Reposit√≥rio com atividades pr√°ticas, organizadas e totalmente comentadas, desenvolvidas ao longo dos m√≥dulos de Big Data utilizando PySpark do curso de An√°lise de Dados da EBAC. 
Cada notebook reflete uma etapa real do fluxo de dados: coleta, prepara√ß√£o, transforma√ß√£o, consultas avan√ßadas, otimiza√ß√£o, integra√ß√£o e an√°lise em larga escala.

---

## üìå Sobre este reposit√≥rio  
Este reposit√≥rio consolida os exerc√≠cios pr√°ticos realizados ao longo dos m√≥dulos do curso de Big Data com PySpark.  
O objetivo √© apresentar, de forma clara e estruturada, a evolu√ß√£o t√©cnica adquirida ao trabalhar com manipula√ß√£o de grandes volumes de dados, otimiza√ß√£o de consultas, opera√ß√µes avan√ßadas de Spark SQL, RDDs, integra√ß√µes, valida√ß√µes e t√©cnicas de machine learning com Spark ML.

Todos os notebooks:

- Est√£o organizados por m√≥dulo  
- Possuem c√≥digo limpo e comentado  
- Focam em boas pr√°ticas, performance e clareza  
- Foram constru√≠dos em Google Colab utilizando PySpark

---

# üöÄ Compet√™ncias Desenvolvidas  

### **1. Consultas SQL Avan√ßadas com PySpark**  
- Integra√ß√£o entre Spark SQL e grandes volumes de dados  
- Otimiza√ß√£o com cache, explain e joins avan√ßados  
- Subconsultas, UDFs e express√µes regulares

### **2. Manipula√ß√£o e Enriquecimento de Dados**  
- Cria√ß√£o de vari√°veis  
- Combina√ß√£o de datasets  
- Filtragem inteligente  
- Limpeza e valida√ß√£o estrutural

### **3. Agrega√ß√µes e An√°lises Complexas**  
- M√©tricas avan√ßadas  
- Rankings  
- S√©ries acumuladas e ponderadas  
- Identifica√ß√£o de padr√µes

### **4. Machine Learning com Spark ML**  
- Pipelines com StringIndexer e PCA  
- Regress√£o linear  
- Agrupamento com K-means e KNN  
- Silhouette Score para avalia√ß√£o

### **5. Processamento em Larga Escala**  
- Configura√ß√£o de SparkSession, SparkConf e SparkContext  
- Manipula√ß√£o de RDDs  
- Transforma√ß√µes map, flatMap, reduceByKey  
- Leitura e escrita de arquivos

### **6. Integra√ß√£o e Valida√ß√£o de Dados**  
- Conex√£o com Google Drive  
- Joins estrat√©gicos  
- Cria√ß√£o de colunas condicionais  
- Regex para valida√ß√£o

---
---

# üéì Objetivo Final  
Este reposit√≥rio serve como portf√≥lio pr√°tico, demonstrando dom√≠nio progressivo de PySpark aplicado a cen√°rios de Big Data ‚Äî da coleta √†s an√°lises avan√ßadas e machine learning.  

---

# üîß Tecnologias Utilizadas  
- PySpark  
- Spark SQL  
- Spark ML  
- RDDs  
- Google Colab  
- Google Drive  
- Python 3  

---

# üì¨ Contato  
**Rafael Agra**  
üîó GitHub: https://github.com/rafaelagra 


Linkedin: https://www.linkedin.com/in/rafael-agra-201005355/

